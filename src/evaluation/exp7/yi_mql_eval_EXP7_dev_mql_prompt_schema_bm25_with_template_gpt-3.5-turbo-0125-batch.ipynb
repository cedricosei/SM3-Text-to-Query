{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import subprocess\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import ast\n",
    "from itertools import permutations\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "# clean the query\n",
    "def clean_mql_query(query):\n",
    "    pattern = re.compile(r'[\\s\\S]*?(?=\\[Q)')\n",
    "    result = pattern.search(query)\n",
    "    if result:\n",
    "        result = result.group()\n",
    "    else:\n",
    "        result = query\n",
    "    return result.replace(\"[MongoDB]:\",\"\").strip()\n",
    "\n",
    "# formulate the queries\n",
    "def add_quotes_to_keys(s):\n",
    "    # add space after \"}\" and before \"}\"\n",
    "    s = re.sub(r'({)', r'\\1 ', str(s))\n",
    "    s = re.sub(r'(})', r' \\1', str(s))\n",
    "    s = re.sub(r'\\{\\s*(\\w+)\\s*:', r\"{ '\\1':\", str(s))\n",
    "    s = re.sub(r',\\s*(\\w+)\\s*:', r\", '\\1':\", str(s))\n",
    "    res = re.sub(r\"Long\\('(\\w+)'\\)\", r'\\1', str(s))\n",
    "    res = res.strip()\n",
    "    # trim the outer \"()\" if exists\n",
    "    if res[0] == \"(\":\n",
    "        if res[-1] == \")\":\n",
    "            res = res[1:-1]\n",
    "        else:\n",
    "            res = res[1:]\n",
    "    # trim the last \",\" if exists\n",
    "    if res[-1] == ',':\n",
    "        res = res[:-1]\n",
    "    return f\"[{res}]\"\n",
    "\n",
    "# string to python object\n",
    "def str_to_obj(s):\n",
    "    try:\n",
    "        return ast.literal_eval(add_quotes_to_keys(s).replace(\"null\", \"None\"))\n",
    "    except (ValueError, SyntaxError) as e:\n",
    "        #if failed return s direct\n",
    "        return s\n",
    "\n",
    "# func to \n",
    "def dicts_to_tuples(list_of_dicts):\n",
    "    try:\n",
    "        list_of_dicts = [tuple(d.values()) for d in list_of_dicts]\n",
    "    except AttributeError:\n",
    "        raise ValueError(f\"Input must be a list of dictionaries {list_of_dicts}\")\n",
    "    finally:\n",
    "        return list_of_dicts\n",
    "\n",
    "def permutation_list(list1):\n",
    "    columns = list(zip(*list1))\n",
    "    perm_columns = permutations(columns)\n",
    "    result = []\n",
    "    for perm in perm_columns:\n",
    "        permuted_list = [tuple(item) for item in zip(*perm)]\n",
    "        result.append(permuted_list)\n",
    "    return result\n",
    "\n",
    "def compare_list(list1, list2, row_permutation=False, column_permutation=False):\n",
    "    if len(list1) != len(list2):\n",
    "        return False\n",
    "    if row_permutation:\n",
    "        def _compare_list(list1, list2):\n",
    "            for item1 in list1:\n",
    "                if item1 not in list2:\n",
    "                    return False\n",
    "            return True\n",
    "    else:\n",
    "        def _compare_list(list1, list2):\n",
    "            return list1 == list2\n",
    "    if column_permutation:\n",
    "        permuted_list1 = permutation_list(list1)\n",
    "        for permuted in permuted_list1:\n",
    "            if _compare_list(permuted, list2):\n",
    "                return True\n",
    "    \n",
    "    return _compare_list(list1, list2)\n",
    "\n",
    "def compare(s1, s2):\n",
    "    o1 = str_to_obj(s1)\n",
    "    o2 = str_to_obj(s2)\n",
    "    if type(o1) == list and type(o2) == list:\n",
    "        try:\n",
    "            t1 = dicts_to_tuples(o1)\n",
    "            t2 = dicts_to_tuples(o2)\n",
    "            return compare_list(t1, t2, True, True)\n",
    "        except Exception as e:\n",
    "            return False\n",
    "\n",
    "    return s1.lower().strip() == s2.lower().strip()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_mongo_query(query:str):\n",
    "    if query.lower().strip()[:9] == \"no answer\":\n",
    "        return query.strip(), 0.0\n",
    "    start_time = time.time()\n",
    "    records = \"[]\"\n",
    "    try:\n",
    "        process = subprocess.Popen([\"mongosh\", \"--quiet\", \"healthcare\"], stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "        stdout, stderr = process.communicate(input=query)\n",
    "        \n",
    "        # Check if there was an error\n",
    "        if stderr:\n",
    "            records = f\"Error: {stderr.strip()}\"\n",
    "        else:\n",
    "            # Check if stdout contains a MongoDB error message\n",
    "            error_pattern = re.compile(r'Error: .*')\n",
    "            error_match = error_pattern.search(stdout.strip())\n",
    "            if error_match:\n",
    "                error_message = error_match.group()\n",
    "                records = error_message\n",
    "            else:\n",
    "                # Extract the results from the output\n",
    "                results_pattern = re.compile(r'\\[([\\s\\S]*?)\\]')\n",
    "                results_match = results_pattern.search(stdout.strip())\n",
    "                if results_match:\n",
    "                    records = results_match.group(1)\n",
    "                    records = re.sub(r'\\s+', ' ', records).strip()\n",
    "    except Exception as e:\n",
    "        records = f\"Error: {str(e)}\"\n",
    "    finally:\n",
    "        end_time = time.time()\n",
    "        execution_time = end_time - start_time\n",
    "        return records, execution_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "root_path = Path.cwd()\n",
    "root_path = root_path.parents[2]\n",
    "# load files:\n",
    "eval_file = root_path / \"data/results/mql\" / \"EXP7/dev/dev_mql_prompt_schema_bm25_with_template_gpt-3.5-turbo-0125-batch.csv\"\n",
    "expert_file = root_path / \"data/dataset/processed_data\" / \"processed_dev.csv\"\n",
    "output_file = root_path / \"data/results/mql\" / \"EXP7/dev/dev_mql_prompt_schema_bm25_with_template_gpt-3.5-turbo-0125-batch-checkpoint.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fa25fbfab4943c49cfb127dd85ba46b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "016e56dcc14044c6ac3290e1a4774ea9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "eval_df = pd.read_csv(eval_file)\n",
    "expert_df = pd.read_csv(expert_file)\n",
    "\n",
    "eval_df[\"cleaned_mql_llm_query\"] = eval_df.progress_apply(lambda x: clean_mql_query(x['answers']), axis=1)\n",
    "eval_df[\"mql_llm_results\"], eval_df[\"mql_llm_time\"] = zip(*eval_df['cleaned_mql_llm_query'].progress_apply(execute_mongo_query))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ed8a65c6a3c488fa4bbf24800fd1203",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "total_df = pd.concat([expert_df, eval_df[[\"cleaned_mql_llm_query\", \"mql_llm_results\", \"mql_llm_time\"]]], axis=1)\n",
    "total_df[\"mql_label\"] = total_df.progress_apply(lambda row: compare(row[\"mql_results\"], row[\"mql_llm_results\"]), axis=1)\n",
    "total_df.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.823"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(total_df[total_df[\"mql_label\"]])/len(total_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def compute_ves(label, time_gt, time_pred):\n",
    "    if time_pred == 0:\n",
    "        return 0\n",
    "    ves = int(label) * math.sqrt(time_gt/time_pred)\n",
    "    return ves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58602bd88d0047cd80a4e86af9701b0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.839861737617344"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(total_df.progress_apply(lambda x: compute_ves(x[\"mql_label\"], x[\"mql_query_time\"], x[\"mql_llm_time\"]), axis=1).sum()/len(total_df)).item()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
